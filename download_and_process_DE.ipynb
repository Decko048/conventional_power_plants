{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Power Plants in Germany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file covers german power plants. It downloads the power plant list from the German Federal Network Agency (BNetzA) and augments it with more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [1. Power Plants in Germany](#1.-Power-Plants-in-Germany)\n",
    "* [2. License](#2.-License)\n",
    "* [3. Prepare the environment](#3.-Prepare-the-environment)\n",
    "* [4. Specify the source URLs:](#4.-Specify-the-source-URLs:)\n",
    "* [5. Define functions](#5.-Define-functions)\n",
    "* [6. Downloads](#6.-Downloads)\n",
    "\t* [6.1 Download the BNetzA power plant list](#6.1-Download-the-BNetzA-power-plant-list)\n",
    "\t* [6.2 Download the Uba Plant list](#6.2-Download-the-Uba-Plant-list)\n",
    "* [7. Translate contents](#7.-Translate-contents)\n",
    "\t* [7.1 Columns](#7.1-Columns)\n",
    "\t* [7.2 Fuel types](#7.2-Fuel-types)\n",
    "\t* [7.3 Power plant status](#7.3-Power-plant-status)\n",
    "\t* [7.4 CHP Capability](#7.4-CHP-Capability)\n",
    "\t* [7.5 EEG](#7.5-EEG)\n",
    "\t* [7.6 UBA Columns](#7.6-UBA-Columns)\n",
    "* [8. Process data](#8.-Process-data)\n",
    "\t* [8.1 Set index to the BNetzA power plant ID](#8.1-Set-index-to-the-BNetzA-power-plant-ID)\n",
    "\t* [8.2 Merge data from UBA List](#8.2-Merge-data-from-UBA-List)\n",
    "\t\t* [8.2.1 case 1-1](#8.2.1-case-1-1)\n",
    "\t\t* [8.2.2 case n-1](#8.2.2-case-n-1)\n",
    "\t\t* [8.2.3 case 1-n](#8.2.3-case-1-n)\n",
    "\t\t* [8.2.4 Merge into plantlist](#8.2.4-Merge-into-plantlist)\n",
    "\t* [8.3 Delete fuels not in focus](#8.3-Delete-fuels-not-in-focus)\n",
    "\t* [8.4 Add Columns for shutdown and retrofit](#8.4-Add-Columns-for-shutdown-and-retrofit)\n",
    "\t* [8.5 Convert input colums to usable data types](#8.5-Convert-input-colums-to-usable-data-types)\n",
    "\t* [8.6 Identify generation technology](#8.6-Identify-generation-technology)\n",
    "\t\t* [8.6.1 Process technology information from UBA list](#8.6.1-Process-technology-information-from-UBA-list)\n",
    "\t\t* [8.6.2 Identify generation technology based on BNetzA information](#8.6.2-Identify-generation-technology-based-on-BNetzA-information)\n",
    "\t* [8.7 Add country code](#8.7-Add-country-code)\n",
    "\t* [8.8 Add efficiency data](#8.8-Add-efficiency-data)\n",
    "\t\t* [8.8.1 Efficiencies from research](#8.8.1-Efficiencies-from-research)\n",
    "\t\t\t* [8.8.1.1 Import data](#8.8.1.1-Import-data)\n",
    "\t\t\t* [8.8.1.2 Plot efficiencies by year of commissioning](#8.8.1.2-Plot-efficiencies-by-year-of-commissioning)\n",
    "\t\t\t* [8.8.1.3 Determine least-squares approximation based on researched data (planned)](#8.8.1.3-Determine-least-squares-approximation-based-on-researched-data-%28planned%29)\n",
    "\t\t\t* [8.8.1.4 Apply efficiency approximation from least squares approximation (planned)](#8.8.1.4-Apply-efficiency-approximation-from-least-squares-approximation-%28planned%29)\n",
    "\t\t* [8.8.2 Efficiencies from literature](#8.8.2-Efficiencies-from-literature)\n",
    "\t\t\t* [8.8.2.1 Import data](#8.8.2.1-Import-data)\n",
    "\t\t\t* [8.8.2.2 Apply efficiency approximation from literature](#8.8.2.2-Apply-efficiency-approximation-from-literature)\n",
    "\t* [8.9 Add geodata](#8.9-Add-geodata)\n",
    "* [9. Define final output](#9.-Define-final-output)\n",
    "\t* [9.1 Verification](#9.1-Verification)\n",
    "\t\t* [9.1.1 Capacities by plant status](#9.1.1-Capacities-by-plant-status)\n",
    "\t\t* [9.1.2 Power plant age](#9.1.2-Power-plant-age)\n",
    "\t\t* [9.1.3 Block size vs year of commissioning](#9.1.3-Block-size-vs-year-of-commissioning)\n",
    "\t* [9.2 Logical checks](#9.2-Logical-checks)\n",
    "\t\t* [9.2.1 Every power plant needs a capacity](#9.2.1-Every-power-plant-needs-a-capacity)\n",
    "\t\t* [9.2.2 Commissioning Dates](#9.2.2-Commissioning-Dates)\n",
    "\t\t* [9.2.3 Compare UBA and BNetzA data](#9.2.3-Compare-UBA-and-BNetzA-data)\n",
    "\t\t\t* [9.2.3.1 Postcodes of BNetzA and UBA lists should match](#9.2.3.1-Postcodes-of-BNetzA-and-UBA-lists-should-match)\n",
    "\t\t\t* [9.2.3.2 Compare Installed capacities](#9.2.3.2-Compare-Installed-capacities)\n",
    "\t\t\t* [9.2.3.3 Compare Comissioning Years](#9.2.3.3-Compare-Comissioning-Years)\n",
    "* [10. Documenting the data package (meta data)](#10.-Documenting-the-data-package-%28meta-data%29)\n",
    "* [11. Write the results to file](#11.-Write-the-results-to-file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FRAUKE: License nur im readme.md\n",
    "- This notebook is published under the LICENSENAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import posixpath\n",
    "import urllib.parse\n",
    "import datetime  \n",
    "import os.path\n",
    "import yaml  # http://pyyaml.org/, pip install pyyaml, conda install pyyaml\n",
    "import json\n",
    "import subprocess\n",
    "import sqlite3\n",
    "import logging\n",
    "\n",
    "from bokeh.charts import Scatter, show\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "output_notebook()\n",
    "%matplotlib inline \n",
    "# FRAUKE: Nutzt ihr matplotlib und bokeh? Falls ihr auf matplotlib\n",
    "# verzichten könnt nehmt es lieber raus, das ist kompliziert zu installieren für den \n",
    "# Nutzer und gibt bei mir auch immer Warnungen aus\n",
    "# Jan: Die imports sollten alle gruppiert am Anfang des Skriptes stehen.\n",
    "\n",
    "# logger is set up\n",
    "logger = logging.getLogger('notebook')\n",
    "logger.setLevel('INFO')\n",
    "nb_root_logger = logging.getLogger()\n",
    "formatter = logging.Formatter(\n",
    "    '%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%d %b %Y %H:%M:%S'\n",
    ")\n",
    "nb_root_logger.handlers[0].setFormatter(formatter)\n",
    "\n",
    "# create download and output folders if they do not exist\n",
    "os.makedirs('download', exist_ok=True)\n",
    "os.makedirs('output', exist_ok=True)\n",
    "os.makedirs(os.path.join('output'),\n",
    "            exist_ok=True)    \n",
    "os.makedirs(os.path.join('output',\n",
    "                         'original_data'),\n",
    "            exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Specify the source URLs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BNetzA Power plant list\n",
    "url_bnetza = ('http://www.bundesnetzagentur.de/SharedDocs/Downloads/DE/'\n",
    "              'Sachgebiete/Energie/Unternehmen_Institutionen/Versorgungssicherheit/'\n",
    "              'Erzeugungskapazitaeten/Kraftwerksliste/Kraftwerksliste_CSV.csv'\n",
    "              '?__blob=publicationFile&v=10')\n",
    "\n",
    "# UBA Power plant list\n",
    "url_uba = ('https://www.umweltbundesamt.de/sites/default/files/medien/'\n",
    "           '1/dokumente/kraftwerke_in_deutschland_2016_kraftwerksdatenbank.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section defines functions used multiple times within this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def downloadandcache(url):\n",
    "    \"\"\"\n",
    "    Download a file into a folder called \"downloads\".\n",
    "    Returns the local filepath.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        Url of a file to be downloaded\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    path = urllib.parse.urlsplit(url).path\n",
    "    filename = posixpath.basename(path)\n",
    "    now = datetime.datetime.now()\n",
    "    datestring = str(now.year) + \"-\" + str(now.month) + \"-\" + str(now.day)\n",
    "    filepath = os.path.join('download', datestring + \"-\" + filename)\n",
    "    filepath_original_data = os.path.join('output',\n",
    "                                          'original_data',\n",
    "                                          filename)\n",
    "    \n",
    "    #check if file exists, otherwise download it\n",
    "    if not os.path.exists(filepath):\n",
    "        logger.info('Downloading file %s', filename) \n",
    "        urllib.request.urlretrieve(url, filepath)\n",
    "        urllib.request.urlretrieve(url, filepath_original_data)\n",
    "    else:\n",
    "        logger.info('Using local file from %s', filepath)\n",
    "    \n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Download the BNetzA power plant list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section downloads the BNetzA power plant list and converts it to a pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bnetza_data_filepath = downloadandcache(url_bnetza)\n",
    "plantlist = pd.read_csv(bnetza_data_filepath,\n",
    "                        skiprows=9,\n",
    "                        sep=';',  # CSV field separator, default is ','\n",
    "                        thousands='.',  # Thousands separator, default is ','\n",
    "                        decimal=',',  # Decimal separator, default is '.'  \n",
    "                        encoding='cp1252')\n",
    "plantlist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Download the Uba Plant list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section downloads the power plant list from the German Federal Environment Agency (UBA) and converts it to a pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uba_data_filepath = downloadandcache(url_uba)\n",
    "plantlist_uba = pd.read_excel(uba_data_filepath, skiprows=9)\n",
    "plantlist_uba.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Translate contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dictionary with the original column names to the new column names is created. This dictionary is used to translate the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Todo (maybe) read as csv\n",
    "dict_columns = {\n",
    "    'Kraftwerksnummer Bundesnetzagentur':\n",
    "        'id',\n",
    "    'Unternehmen':\n",
    "        'company',\n",
    "    'Kraftwerksname':\n",
    "        'name',\n",
    "    'PLZ\\n(Standort Kraftwerk)':\n",
    "        'postcode',\n",
    "    'Ort\\n(Standort Kraftwerk)':\n",
    "        'city',\n",
    "    'Straße und Hausnummer (Standort Kraftwerk)':\n",
    "        'street',\n",
    "    'Bundesland':\n",
    "        'state',\n",
    "    'Blockname':\n",
    "        'block',\n",
    "    ('Aufnahme der kommerziellen Stromerzeugung der derzeit in Betrieb '\n",
    "     'befindlichen Erzeugungseinheit\\n(Jahr)'):\n",
    "        'commissioned',\n",
    "    ('Kraftwerksstatus \\n(in Betrieb/\\nvorläufig stillgelegt/\\nsaisonale '\n",
    "     'Konservierung\\nReservekraftwerk/\\nSonderfall)'):\n",
    "        'status',\n",
    "    ('Kraftwerksstatus \\n(in Betrieb/\\nvorläufig stillgelegt/\\nsaisonale '\n",
    "     'Konservierung\\nGesetzlich an Stilllegung gehindert/\\nSonderfall)'):\n",
    "        'status',    \n",
    "    'Energieträger':\n",
    "        'fuel_basis',\n",
    "    ('Spezifizierung \"Mehrere Energieträger\" und \"Sonstige Energieträger\" - '\n",
    "     'Hauptbrennstoff'): 'fuel_multiple1',\n",
    "    'Spezifizierung \"Mehrere Energieträger\" - Zusatz- / Ersatzbrennstoffe':\n",
    "        'fuel_multiple2',\n",
    "    ('Auswertung\\nEnergieträger (Zuordnung zu einem Hauptenergieträger bei '\n",
    "     'Mehreren Energieträgern)'):\n",
    "        'fuel',\n",
    "    'Vergütungsfähig nach EEG\\n(ja/nein)':\n",
    "        'eeg',\n",
    "    'Wärmeauskopplung (KWK)\\n(ja/nein)':\n",
    "        'chp',\n",
    "    'Netto-Nennleistung (elektrische Wirkleistung) in MW':\n",
    "        'capacity',\n",
    "    ('Bezeichnung Verknüpfungspunkt (Schaltanlage) mit dem Stromnetz der '\n",
    "     'Allgemeinen Versorgung gemäß Netzbetreiber'):\n",
    "        'network_node',\n",
    "    'Netz- oder Umspannebene des Anschlusses in kV':\n",
    "        'voltage',\n",
    "    'Name Stromnetzbetreiber':\n",
    "        'network_operator',\n",
    "    'Kraftwerksname / Standort':\n",
    "        'uba_name',\n",
    "    'Betreiber ':\n",
    "        'uba_company',\n",
    "    'Standort-PLZ':\n",
    "        'uba_postcode',\n",
    "    'Kraftwerksstandort':\n",
    "        'uba_city',\n",
    "    'Elektrische Bruttoleistung (MW)':\n",
    "        'uba_capacity',\n",
    "    'Fernwärme-leistung (MW)':\n",
    "        'uba_chp_capacity',\n",
    "    'Inbetriebnahme  (ggf. Ertüchtigung)':\n",
    "        'uba_commissioned',\n",
    "    'Anlagenart':\n",
    "        'uba_technology',\n",
    "    'Primärenergieträger':\n",
    "        'uba_fuel',\n",
    "}\n",
    "plantlist.rename(columns=dict_columns, inplace=True)\n",
    "\n",
    "# Check if all columns have been translated\n",
    "for columnnames in plantlist.columns:\n",
    "    # if columnnames not in dict_columns.values():\n",
    "    if columnnames not in dict_columns.values():\n",
    "        logger.error(\"Untranslated column: \"+ columnnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Fuel types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_fuels = {\n",
    "    'Steinkohle': 'coal',\n",
    "    'Erdgas': 'natural_gas',\n",
    "    'Braunkohle': 'lignite',\n",
    "    'Kernenergie': 'uranium',\n",
    "    'Pumpspeicher': 'pumped_storage',\n",
    "    'Biomasse': 'biomass',\n",
    "    'Mineralölprodukte': 'oil',\n",
    "    'Laufwasser': 'hydro',\n",
    "    'Sonstige Energieträger\\n(nicht erneuerbar) ': 'other_non_renewable',\n",
    "    'Abfall': 'waste',\n",
    "    'Speicherwasser (ohne Pumpspeicher)': 'reservoir',\n",
    "    'Unbekannter Energieträger\\n(nicht erneuerbar)': 'unknown_non_renewable',\n",
    "    'Mehrere Energieträger\\n(nicht erneuerbar)': 'multiple_non_renewable',\n",
    "    'Deponiegas': 'gas_landfill',\n",
    "    'Windenergie (Onshore-Anlage)': 'wind_onshore',\n",
    "    'Windenergie (Offshore-Anlage)': 'wind_offshore',\n",
    "    'Solare Strahlungsenergie': 'solar',\n",
    "    'Klärgas': 'gas_sewage',\n",
    "    'Geothermie': 'geothermal',\n",
    "    'Grubengas': 'gas_mine'\n",
    "}\n",
    "plantlist[\"fuel\"].replace(dict_fuels, inplace=True)\n",
    "\n",
    "# Check if all fuels have been translated\n",
    "for fuelnames in plantlist[\"fuel\"].unique():\n",
    "    if fuelnames not in dict_fuels.values():\n",
    "        logger.error(\"Untranslated fuel: \" + fuelnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Power plant status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Todo (maybe) read as csv\n",
    "dict_plantstatus = {\n",
    "    'in Betrieb': 'operating',\n",
    "    'In Betrieb': 'operating',\n",
    "    'vorläufig stillgelegt': 'shutdown_temporary',\n",
    "    'Vorläufig stillgelegt': 'shutdown_temporary',\n",
    "    'Vorläufig Stillgelegt': 'shutdown_temporary',    \n",
    "    'Sonderfall': 'special_case',\n",
    "    'saisonale Konservierung': 'seasonal_conservation',\n",
    "    'Saisonale Konservierung': 'seasonal_conservation',    \n",
    "    'Reservekraftwerk':'reserve',\n",
    "    'Endgültig Stillgelegt 2011': 'shutdown_2011',\n",
    "    'Endgültig Stillgelegt 2012': 'shutdown_2012',\n",
    "    'Endgültig Stillgelegt 2013': 'shutdown_2013',\n",
    "    'Endgültig Stillgelegt 2014': 'shutdown_2014',\n",
    "    'Endgültig Stillgelegt 2015': 'shutdown_2015',\n",
    "    'Endgültig stillgelegt 2015': 'shutdown_2015',\n",
    "    'Endgültig Stillgelegt 2016': 'shutdown_2016',\n",
    "    'Gesetzlich an Stilllegung gehindert': 'operating',    \n",
    "}  \n",
    "plantlist['status'].replace(dict_plantstatus, inplace=True) \n",
    "\n",
    "# Check if all fuels have been translated\n",
    "for statusnames in plantlist['status'].unique():\n",
    "    if statusnames not in dict_plantstatus.values():\n",
    "        logger.error('Untranslated plant status: '+ statusnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 CHP Capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_yesno ={\n",
    "    'Nein': 'no',\n",
    "    'nein': 'no',\n",
    "    'Ja': 'yes',\n",
    "    'ja': 'yes',    \n",
    "}\n",
    "plantlist['chp'].replace(dict_yesno, inplace=True)\n",
    "\n",
    "# Check if all fuels have been translated\n",
    "for chpnames in plantlist['chp'].unique():\n",
    "    if (chpnames not in dict_yesno.values()) & (str(chpnames) != 'nan'):\n",
    "        logger.error('Untranslated chp capability: ' + str(chpnames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plantlist['eeg'].replace(dict_yesno, inplace=True)\n",
    "\n",
    "# Check if all fuels have been translated\n",
    "for eegnames in plantlist['eeg'].unique():\n",
    "    if (eegnames not in dict_yesno.values()) & (str(eegnames) != 'nan'):\n",
    "        logger.error('Untranslated EEG type: ' + str(eegnames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 UBA Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate the UBA Column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Todo (maybe) read as csv\n",
    "dict_uba_columns = {\n",
    "    'Kraftwerksname / Standort': 'uba_name',\n",
    "    'Betreiber ': 'uba_company',\n",
    "    'Standort-PLZ': 'uba_postcode',\n",
    "    'Kraftwerksstandort': 'uba_city',\n",
    "    'Elektrische Bruttoleistung (MW)': 'uba_capacity',\n",
    "    'Fernwärme-leistung (MW)': 'uba_chp_capacity',\n",
    "    'Inbetriebnahme  (ggf. Ertüchtigung)': 'uba_commissioned',\n",
    "    'Anlagenart': 'uba_technology',\n",
    "    'Primärenergieträger': 'uba_fuel',\n",
    "    'Bundesland':'uba_state',\n",
    "}\n",
    "plantlist_uba.rename(columns=dict_uba_columns, inplace=True)\n",
    "\n",
    "# Check if all columns have been translated\n",
    "for columnnames in plantlist_uba.columns:\n",
    "    if columnnames not in dict_uba_columns.values():\n",
    "        logger.error('Untranslated column: ' + columnnames)\n",
    "        \n",
    "# Prepare for matching\n",
    "plantlist_uba['uba_id_string'] = (plantlist_uba['uba_name'] \n",
    "                                  + '_' \n",
    "                                  + plantlist_uba['uba_fuel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Set index to the BNetzA power plant ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set Index of BNetzA power plant list to Kraftwerksnummer_Bundesnetzagentur\n",
    "plantlist['bnetza_id'] = plantlist['id']\n",
    "plantlist = plantlist.set_index('id')\n",
    "plantlist.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Merge data from UBA List\n",
    "In this section a hand-researched list is used to match the power plants from the UBA list to the BNetzA list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read matching list\n",
    "matchinglist=pd.read_csv(\n",
    "    os.path.join('input', 'matching_bnetza_uba.csv'), \n",
    "    skiprows=0,\n",
    "    sep=',',  # CSV field separator, default is ','\n",
    "    thousands=',',  # Thousands separator, default is ','\n",
    "    decimal='.',  # Decimal separator, default is '.')  \n",
    "    encoding='cp1252')\n",
    "matchinglist['uba_id_string'] = (matchinglist['uba_match_name'] \n",
    "                                 + '_' \n",
    "                                 + matchinglist['uba_match_fuel'])\n",
    "matchinglist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.1 case 1-1\n",
    "Matching: 1-1 One BNetzA ID to one UBA-ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match1t1 = matchinglist[\n",
    "    (matchinglist.duplicated(subset=['uba_id_string'], keep=False) == False) \n",
    "    & (matchinglist.duplicated(subset=['ID BNetzA'], keep=False) == False)]\n",
    "match1t1 = pd.merge(match1t1, plantlist_uba,\n",
    "                    left_on='uba_id_string', \n",
    "                    right_on='uba_id_string',\n",
    "                    how='left')\n",
    "match1t1 = match1t1.set_index('ID BNetzA')\n",
    "\n",
    "#Add comment\n",
    "match1t1['merge_comment'] = ('List matching type: Single UBA power plant '\n",
    "                             'assigned to single BNetzA power plant')\n",
    "\n",
    "match1t1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.2 case n-1\n",
    "Match multiple BNetza IDs to one UBA ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Matching structure (example): \n",
    "# bnetza_id uba_id\n",
    "# 1         1\n",
    "# 2         1\n",
    "# 3         1\n",
    "# 4         2\n",
    "# 5         2\n",
    "\n",
    "# Get relevant entries from the matchinglist and merge the corresponding \n",
    "# UBA Data to the list.\n",
    "matchnt1= matchinglist[\n",
    "    (matchinglist.duplicated(subset=['uba_id_string'], keep=False) == True)\n",
    "    & (matchinglist.duplicated(subset=['ID BNetzA'], keep=False)== False)]\n",
    "matchnt1 = pd.merge(matchnt1, plantlist_uba,\n",
    "                    left_on='uba_id_string', right_on='uba_id_string', how='left')\n",
    "matchnt1 = matchnt1.set_index('ID BNetzA')\n",
    "\n",
    "# Import BNetzA Capacities and CHP criterion into matchnt1 dataframe\n",
    "plantlist_capacities = pd.DataFrame(plantlist[['capacity', 'chp']]).rename(\n",
    "    columns={'capacity': 'capacity_bnetza', 'chp': 'chp_bnetza'})\n",
    "matchnt1 = pd.merge(matchnt1, plantlist_capacities,\n",
    "                    left_index=True, right_index=True, how='left')\n",
    "\n",
    "# Get sum of BNetzA Capacitites for each UBA Index and merge into matchnt1 dataframe\n",
    "plantlist_uba_capacitysum = pd.DataFrame(\n",
    "    matchnt1.groupby('uba_id_string').sum()['capacity_bnetza']).rename(\n",
    "        columns={'capacity_bnetza': 'capacity_bnetza_aggregate'})\n",
    "matchnt1 = pd.merge(matchnt1, plantlist_uba_capacitysum,\n",
    "                    left_on='uba_id_string', right_index=True, how='left')\n",
    "\n",
    "# Scale UBA Capacities based BNetzA Data\n",
    "matchnt1['uba_capacity_scaled'] = (matchnt1['uba_capacity']\n",
    "                                   * matchnt1['capacity_bnetza']\n",
    "                                   / matchnt1['capacity_bnetza_aggregate'])\n",
    "\n",
    "# determine sum of capacities with chp capability and add to matchnt1\n",
    "plantlist_uba_chp_capacities = matchnt1[(matchnt1['chp_bnetza'] == 'yes')]\n",
    "plantlist_uba_chp_capacitysum = pd.DataFrame(\n",
    "    plantlist_uba_chp_capacities.groupby('uba_id_string')\n",
    "    .sum()['capacity_bnetza']) \n",
    "plantlist_uba_chp_capacitysum = plantlist_uba_chp_capacitysum.rename(\n",
    "    columns={'capacity_bnetza': 'capacity_bnetza_with_chp'})\n",
    "matchnt1 = pd.merge(matchnt1, plantlist_uba_chp_capacitysum,\n",
    "                    left_index=True, right_index=True, how='left')\n",
    "\n",
    "matchnt1['uba_chp_capacity_scaled'] = (matchnt1['uba_chp_capacity']\n",
    "                                       * matchnt1['capacity_bnetza']\n",
    "                                       / matchnt1['capacity_bnetza_with_chp'])\n",
    "\n",
    "# Change column names for merge later on\n",
    "matchnt1['uba_chp_capacity_original'] = matchnt1['uba_chp_capacity']\n",
    "matchnt1['uba_chp_capacity'] = matchnt1['uba_chp_capacity_scaled']\n",
    "matchnt1['uba_capacity_original'] = matchnt1['uba_capacity']\n",
    "matchnt1['uba_capacity'] = matchnt1['uba_capacity_scaled']\n",
    "\n",
    "#Add comment\n",
    "matchnt1['merge_comment'] = ('List matching type: UBA capacity distributed '\n",
    "                             'proportionally to multiple BNetzA power plants')\n",
    "\n",
    "matchnt1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.3 case 1-n\n",
    "1-n Case here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The resulting DataFrame should be called \"match1tn\"\n",
    "# Matching structure: \n",
    "# bnetza_id uba_id\n",
    "# 1         1\n",
    "# 1         2\n",
    "# 1         3\n",
    "# 2         4\n",
    "# 2         5\n",
    "\n",
    "# Get relevant entries from the matchinglist and merge the corresponding UBA Data to the list.\n",
    "match1tn= matchinglist[\n",
    "    (matchinglist.duplicated(subset=['ID BNetzA'], keep=False) == True) & \n",
    "    (matchinglist.duplicated(subset=['uba_id_string'], keep=False)== False)]\n",
    "match1tn = pd.merge(match1tn, plantlist_uba,\n",
    "                    left_on='uba_id_string', right_on='uba_id_string', how='left')\n",
    "match1tn = match1tn.set_index('ID BNetzA')\n",
    "match1tn.head()\n",
    "\n",
    "# Import BNetzA Capacities and CHP criterion into match1tn dataframe\n",
    "plantlist_capacities = pd.DataFrame(plantlist[['capacity','chp']]).rename(\n",
    "    columns = {'capacity': 'capacity_bnetza', 'chp': 'chp_bnetza'})\n",
    "match1tn = pd.merge(match1tn, plantlist_capacities,\n",
    "                    left_index=True, right_index=True, how='left')\n",
    "match1tn.index.names=['ID BNetzA']\n",
    "match1tn.head()\n",
    "\n",
    "# Get sum of UBA Capacitites per BNetzA Index and merge to match1tn dataframe\n",
    "plantlist_bnetza_capacitysum = pd.DataFrame(\n",
    "    match1tn.groupby(match1tn.index).sum()['uba_capacity'])\n",
    "plantlist_bnetza_capacitysum = plantlist_bnetza_capacitysum.rename(\n",
    "    columns={'uba_capacity':'uba_capacity_aggregate'})\n",
    "match1tn = pd.merge(match1tn, plantlist_bnetza_capacitysum,\n",
    "                    left_index=True, right_index=True, how='left')\n",
    "\n",
    "# Get sum of UBA CHP Capacities per BNetzA Index and merge to match1tn dataframe\n",
    "plantlist_bnetza_chp_capacitysum = pd.DataFrame(\n",
    "    match1tn.groupby(match1tn.index).sum()['uba_chp_capacity'])\n",
    "plantlist_bnetza_chp_capacitysum = plantlist_bnetza_chp_capacitysum.rename(\n",
    "    columns={'uba_chp_capacity': 'uba_chp_capacity_aggregate'})\n",
    "match1tn = pd.merge(match1tn, plantlist_bnetza_chp_capacitysum,\n",
    "                    left_index=True, right_index=True, how='left')\n",
    "\n",
    "# Get UBA Technology for each BNetzA Index and merge into match1tn dataframe \n",
    "## Option 1: Take all technologies and merge them\n",
    "#match1tn['uba_technology_aggregate'] = pd.DataFrame(\n",
    "#    match1tn.groupby(match1tn.index)\n",
    "#    .transform(lambda x: ', '.join(x))['uba_technology'])\n",
    "## Option 2 (currently preferred): Take technology with highest occurence\n",
    "match1tn['uba_technology_aggregate'] = pd.DataFrame(\n",
    "    match1tn.groupby(match1tn.index)['uba_technology']\n",
    "    .agg(lambda x: x.value_counts().index[0]))\n",
    "\n",
    "# Get UBA Plant name\n",
    "match1tn['uba_name_aggregate'] = pd.DataFrame(\n",
    "    match1tn.groupby(match1tn.index).transform(lambda x: ', '.join(x))['uba_name'])\n",
    "\n",
    "# Get UBA company name\n",
    "match1tn['uba_company_aggregate'] = pd.DataFrame(\n",
    "    match1tn.groupby(match1tn.index)['uba_company']\n",
    "    .agg(lambda x:x.value_counts().index[0]))\n",
    "\n",
    "# Change column names for merge later on\n",
    "match1tn = match1tn.rename(\n",
    "    columns={'uba_chp_capacity': 'uba_chp_capacity_original',\n",
    "             'uba_capacity': 'uba_capacity_original',\n",
    "             'uba_chp_capacity_aggregate': 'uba_chp_capacity',\n",
    "             'uba_capacity_aggregate': 'uba_capacity'})\n",
    "\n",
    "#Add comment\n",
    "match1tn['merge_comment'] = ('List matching type: Multiple UBA capacities '\n",
    "                             'aggregated to single BNetzA power plant')\n",
    "\n",
    "# Drop duplicate rows and keep first entry\n",
    "match1tn = match1tn.reset_index().drop_duplicates(subset='ID BNetzA',keep='first').set_index('ID BNetzA')\n",
    "\n",
    "match1tn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.4 Merge into plantlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge the UBA DataFrames\n",
    "# Merge first two dataframes\n",
    "plantlist_uba_for_merge = match1t1.append(matchnt1)\n",
    "\n",
    "# Add third dataframe\n",
    "plantlist_uba_for_merge = plantlist_uba_for_merge.append(match1tn)\n",
    "\n",
    "# Merge plantlist_uba_for_merge into the plantlist\n",
    "plantlist = pd.merge(plantlist, plantlist_uba_for_merge,\n",
    "                     left_index=True, right_index=True, how='left')\n",
    "\n",
    "plantlist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Delete fuels not in focus\n",
    "Here, solar, wind onshore. and wind offshore technologies are deleted from the list, as they are handled by another datapackage. Furthermore, aggregate values are excluded as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete solar, wind onshore, and wind offshore\n",
    "plantlist = plantlist[(plantlist['fuel'] != 'solar') \n",
    "                       & (plantlist['fuel'] != 'wind_onshore') \n",
    "                       & (plantlist['fuel'] != 'wind_offshore')]\n",
    "\n",
    "# Delete aggrgate values\n",
    "plantlist = plantlist[(plantlist['company'] != 'EEG-Anlagen < 10 MW') \n",
    "                       & (plantlist['company'] != 'Nicht-EEG-Anlagen < 10 MW')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 Add Columns for shutdown and retrofit\n",
    "Extract the year when plants were shutdown or retrofit, using regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add columns with empty data\n",
    "plantlist['shutdown'] = 'NaN'\n",
    "\n",
    "plantlist['shutdown'] = pd.to_numeric(\n",
    "    plantlist['status'].str.extract('[\\w].+(\\d\\d\\d\\d)', expand=False), \n",
    "    errors='coerce')\n",
    "plantlist.loc[plantlist['shutdown'] > 0, 'status'] = 'shutdown'\n",
    "\n",
    "# Fill retrofit data column\n",
    "# Identify restrofit dates in UBA list\n",
    "plantlist['retrofit'] = pd.to_numeric(\n",
    "    plantlist['uba_commissioned'].str.extract('[(.+](\\d\\d\\d\\d)', expand=False), \n",
    "    errors='coerce')\n",
    "\n",
    "# Split multiple commissioning dates as listed in UBA\n",
    "plantlist['uba_commissioned_1'] = pd.to_numeric(\n",
    "    plantlist['uba_commissioned'].str.extract('(\\d\\d\\d\\d)', expand=False), \n",
    "    errors='coerce')\n",
    "plantlist.loc[plantlist['uba_commissioned_1'].isnull(), 'uba_commissioned_1'] = pd.to_numeric(\n",
    "    plantlist['uba_commissioned'].str.extract('(\\d\\d\\d\\d).+[\\w]', expand=False), \n",
    "    errors='coerce')\n",
    "plantlist['uba_commissioned_2'] = pd.to_numeric(\n",
    "    plantlist['uba_commissioned'].str.extract('[\\w].+(\\d\\d\\d\\d).+[\\w]', expand=False),\n",
    "    errors='coerce')\n",
    "plantlist['uba_commissioned_3'] = pd.to_numeric(\n",
    "    plantlist['uba_commissioned'].str.extract('[\\w].+(\\d\\d\\d\\d)', expand=False),\n",
    "    errors='coerce')\n",
    "\n",
    "plantlist.loc[plantlist['retrofit'] == plantlist['uba_commissioned_1'], 'uba_commissioned_1'] = ''\n",
    "plantlist.loc[plantlist['retrofit'] == plantlist['uba_commissioned_2'], 'uba_commissioned_2'] = ''\n",
    "plantlist.loc[plantlist['retrofit'] == plantlist['uba_commissioned_3'], 'uba_commissioned_3'] = ''\n",
    "\n",
    "# Split multiple commissioning dates as listed in BNetzA\n",
    "plantlist['commissioned_1'] = pd.to_numeric(\n",
    "    plantlist['commissioned'].str.extract('(\\d\\d\\d\\d)', expand=False), \n",
    "    errors='coerce')\n",
    "plantlist.loc[plantlist['commissioned_1'].isnull(), 'commissioned_1'] = pd.to_numeric(\n",
    "    plantlist['commissioned'].str.extract('(\\d\\d\\d\\d).+[\\w]', expand=False),\n",
    "    errors='coerce')\n",
    "plantlist['commissioned_2'] = pd.to_numeric(\n",
    "    plantlist['commissioned'].str.extract('[\\w].+(\\d\\d\\d\\d).+[\\w]', expand=False),\n",
    "    errors='coerce')\n",
    "plantlist['commissioned_3'] = pd.to_numeric(\n",
    "    plantlist['commissioned'].str.extract('[\\w].+(\\d\\d\\d\\d)', expand=False),\n",
    "    errors='coerce')\n",
    "\n",
    "# Show plantlist\n",
    "plantlist[plantlist['status'] == 'shutdown']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 Convert input colums to usable data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plantlist['capacity_float'] = pd.to_numeric(\n",
    "    plantlist['capacity'], \n",
    "    errors='coerce')\n",
    "plantlist['commissioned_float'] = pd.to_numeric(\n",
    "    plantlist[['commissioned','commissioned_1','commissioned_2','commissioned_3']].max(axis=1),\n",
    "    errors='coerce')\n",
    "plantlist['retrofit_float'] = pd.to_numeric(\n",
    "    plantlist['retrofit'],\n",
    "    errors='coerce')\n",
    "plantlist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6 Identify generation technology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6.1 Process technology information from UBA list\n",
    "Technologies describes the turbine specification etc., and \"type\" determines how the plant is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Todo (maybe): read as csv\n",
    "\n",
    "# Split uba_technology information into technology (GT, CC,...) and type (HKW, IKW, ...)\n",
    "plantlist['technology'] = plantlist['uba_technology']\n",
    "plantlist['type'] = plantlist['uba_technology']\n",
    "\n",
    "dict_technology = {\n",
    "    'GT': 'GT',\n",
    "    'GuD': 'CC',\n",
    "    'DKW': 'ST',\n",
    "    'LWK': 'ROR',\n",
    "    'PSW': 'PSP',\n",
    "    'DWR': 'ST',  #Pressurized water reactor\n",
    "    'G/AK': 'GT',  #GT with heat recovery\n",
    "    'SWR': 'ST',  #boiling water reactor\n",
    "    'SWK': 'SPP',  #storage power plant\n",
    "    'SSA': '',  #bus bar\n",
    "    'HKW (DT)': 'ST',\n",
    "    'HKW / GuD': 'CC',\n",
    "    'GuD / HKW': 'CC',\n",
    "    'IKW / GuD': 'CC',\n",
    "    'IKW /GuD': 'CC',\n",
    "    'HKW / SSA': '',\n",
    "    'IKW / SSA': '',\n",
    "    'HKW': '',\n",
    "    'IKW': '',\n",
    "    'IKW / HKW': '',\n",
    "    'WEA': 'WT'\n",
    "}\n",
    "plantlist['technology'].replace(dict_technology, inplace=True)\n",
    "plantlist['technology'].unique()\n",
    "\n",
    "# Check if all technologies have been translated\n",
    "for technology in plantlist['technology'].unique():\n",
    "    if (technology not in dict_technology.values()) & (str(technology) != 'nan'):\n",
    "        logger.error('Untranslated technology: ' + str(technology))\n",
    "\n",
    "# Translate types\n",
    "dict_type = {\n",
    "    'HKW': 'CHP',  #thermal power plant,\n",
    "    'HKW (DT)': 'CHP',\n",
    "    'IKW': 'IPP',  #industrial power plant         \n",
    "    'HKW / GuD': 'CHP',\n",
    "    'GuD / HKW': 'CHP',\n",
    "    'IKW / GuD': 'IPP',\n",
    "    'IKW /GuD': 'IPP',\n",
    "    'IKW / SSA': 'IPP',\n",
    "    'HKW / SSA': 'CHP',\n",
    "    'IKW / HKW': 'CHP',\n",
    "    'GT': '',\n",
    "    'GuD': '',\n",
    "    'DKW': '',\n",
    "    'LWK': '',\n",
    "    'PSW': '',\n",
    "    'DWR': '',  #Pressurized water reactor\n",
    "    'G/AK': 'CHP',  #GT with heat recovery\n",
    "    'SWR': '',  #boiling water reactor\n",
    "    'SWK': '',  #storage power plant\n",
    "    'SSA': '', \n",
    "    'WEA': '',\n",
    "}\n",
    "plantlist['type'].replace(dict_type, inplace=True)\n",
    "plantlist['type'].unique()\n",
    "\n",
    "# Check if all types have been translated\n",
    "for type in plantlist['type'].unique():\n",
    "    if (type not in dict_type.values()) & (str(type) != 'nan'):\n",
    "        logger.error('Untranslated type: ' + str(type))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6.2 Identify generation technology based on BNetzA information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set technology based on fuels\n",
    "\n",
    "plantlist.loc[(plantlist['fuel'] == 'uranium') & ((plantlist['technology'] == '') | (\n",
    "    plantlist['technology'].isnull())), 'technology'] = 'ST'\n",
    "plantlist.loc[(plantlist['fuel'] == 'lignite') & ((plantlist['technology'] == '') | (\n",
    "    plantlist['technology'].isnull())), 'technology'] = 'ST'\n",
    "plantlist.loc[(plantlist['fuel'] == 'coal') & ((plantlist['technology'] == '') | (\n",
    "    plantlist['technology'].isnull())), 'technology'] = 'ST'\n",
    "plantlist.loc[(plantlist['fuel'] == 'hydro') & ((plantlist['technology'] == '') | (\n",
    "    plantlist['technology'].isnull())), 'technology'] = 'ROR'\n",
    "plantlist.loc[(plantlist['fuel'] == 'pumped_storage') & ((plantlist[\n",
    "    'technology'] == '') | (plantlist['technology'].isnull())), 'technology'] = 'PSP'\n",
    "plantlist.loc[(plantlist['fuel'] == 'reservoir') & ((plantlist['technology'] == '') | (\n",
    "    plantlist['technology'].isnull())), 'technology'] = 'RES'\n",
    "\n",
    "# Set technology based on name and block information combined with fuels (e.g. combined-cycle, gas turbine)\n",
    "# Define technology CC as combination of GT and DT\n",
    "plantlist.loc[((plantlist['name'].str.contains(\"GT\")) | (plantlist['block'].str.contains(\"GT\")))\n",
    "              & ((plantlist['name'].str.contains(\"DT\")) | (plantlist['block'].str.contains(\"DT\")))\n",
    "              & ((plantlist['technology'] == '') | (plantlist['technology'].isnull())), 'technology'] = 'CC'\n",
    "# Define technology CC if specified as GuD\n",
    "plantlist.loc[((plantlist['name'].str.contains(\"GuD\")) | (plantlist['block'].str.contains(\"GuD\"))\n",
    "               | (plantlist['name'].str.contains(\"GUD\")) | (plantlist['name'].str.contains(\"GUD\")))\n",
    "              & ((plantlist['technology'] == '') | (plantlist['technology'].isnull())), 'technology'] = 'CC'\n",
    "# Define technology GT\n",
    "plantlist.loc[((plantlist['name'].str.contains(\"GT\"))\n",
    "               | (plantlist['block'].str.contains(\"GT\"))\n",
    "               | (plantlist['name'].str.contains(\"Gasturbine\"))\n",
    "               | (plantlist['block'].str.contains(\"Gasturbine\")))\n",
    "              & ((plantlist['technology'] == '') | (plantlist['technology'].isnull())), 'technology'] = 'GT'\n",
    "# Define technology ST\n",
    "plantlist.loc[((plantlist['name'].str.contains(\"DT\"))\n",
    "               | (plantlist['block'].str.contains(\"DT\"))\n",
    "               | (plantlist['name'].str.contains(\"Dampfturbine\"))\n",
    "               | (plantlist['block'].str.contains(\"Dampfturbine\"))\n",
    "               | (plantlist['name'].str.contains(\"Dampfkraftwerk\"))\n",
    "               | (plantlist['block'].str.contains(\"Dampfkraftwerk\"))\n",
    "               | (plantlist['name'].str.contains(\"DKW\"))\n",
    "               | (plantlist['block'].str.contains(\"DKW\")))\n",
    "              & ((plantlist['technology'] == '') | (plantlist['technology'].isnull())), 'technology'] = 'ST'\n",
    "# Define technology CB\n",
    "plantlist.loc[((plantlist['name'].str.contains(\"motor\"))\n",
    "               | (plantlist['block'].str.contains(\"motor\"))\n",
    "               | (plantlist['name'].str.contains(\"Motor\"))\n",
    "               | (plantlist['block'].str.contains(\"Motor\")))\n",
    "              & ((plantlist['technology'] == '') | (plantlist['technology'].isnull())), 'technology'] = 'CB'\n",
    "\n",
    "# Set technology ST for all technologies which could not be identified\n",
    "plantlist.loc[((plantlist['technology'] == '')\n",
    "               | (plantlist['technology'].isnull())), 'technology'] = 'ST'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7 Add country code\n",
    "Some power plants are in Austria, Switzerland, or Luxembourg. As they are sometimes part of the German electricity system, they are included here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add country Code\n",
    "plantlist['country_code'] = plantlist['state']\n",
    "dict_state_country = {\n",
    "    'Brandenburg': 'DE',\n",
    "    'Baden-Württemberg': 'DE',\n",
    "    'Niedersachsen': 'DE',\n",
    "    'Bayern': 'DE',\n",
    "    'Mecklenburg-Vorpommern': 'DE',\n",
    "    'Sachsen-Anhalt': 'DE',\n",
    "    'Hessen': 'DE',\n",
    "    'Nordrhein-Westfalen': 'DE',\n",
    "    'Berlin': 'DE',\n",
    "    'Saarland': 'DE',\n",
    "    'Thüringen': 'DE',\n",
    "    'Sachsen': 'DE',\n",
    "    'Bremen': 'DE',\n",
    "    'Schleswig-Holstein': 'DE',\n",
    "    'Hamburg': 'DE',\n",
    "    'Rheinland-Pfalz': 'DE',\n",
    "    'Österreich': 'AT',\n",
    "    'Luxemburg': 'LU',\n",
    "    'Schweiz': 'CH',\n",
    "}\n",
    "plantlist['country_code'].replace(dict_state_country, inplace=True)\n",
    "\n",
    "# Check if all types have been translated\n",
    "for plant_type in plantlist['country_code'].unique():\n",
    "    if (plant_type not in dict_state_country.values()) & (str(plant_type) != 'nan'):\n",
    "        logger.error('Untranslated type: ' + str(plant_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.8 Add efficiency data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.8.1 Efficiencies from research\n",
    "\n",
    "This sections adds efficiency data. These values have been researched by hand.  \n",
    "\n",
    "The source of each value is given in the column \"efficiency_source\". \n",
    "\n",
    "Additionally, a rating of the source has been done starting from A (e.g. website of the power plants operator) to C (e.g. Article in local newspaper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.8.1.1 Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Efficiencies\n",
    "data_efficiencies_bnetza = pd.read_csv(os.path.join('input', 'input_efficiency_de.csv'),\n",
    "                                     sep=',',  # CSV field separator, default is ','\n",
    "                                     decimal='.',  # Decimal separator, default is '.')\n",
    "                                     index_col='id',\n",
    "                                     encoding='utf8')\n",
    "data_efficiencies_bnetza['efficiency_net'] = pd.to_numeric(\n",
    "    data_efficiencies_bnetza['efficiency_net'],\n",
    "    errors='coerce') \n",
    "\n",
    "data_efficiencies_bnetza = data_efficiencies_bnetza.dropna(subset=['efficiency_net'])\n",
    "\n",
    "plantlist = pd.merge(\n",
    "    plantlist, \n",
    "    data_efficiencies_bnetza, \n",
    "    left_index=True, \n",
    "    right_index=True, \n",
    "    how='left')\n",
    "plantlist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.8.1.2 Plot efficiencies by year of commissioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot efficiencies for lignite, coal, oil, and natural gas\n",
    "plantlist_for_efficiency_analysis = plantlist\n",
    "plantlist_for_efficiency_analysis = plantlist_for_efficiency_analysis.dropna(subset=['efficiency_net'])\n",
    "fuel_for_plot = ['lignite', 'coal', 'oil', 'natural_gas']\n",
    "plantlist_for_efficiency_analysis = plantlist_for_efficiency_analysis[\n",
    "    plantlist_for_efficiency_analysis.fuel.isin(fuel_for_plot)]\n",
    "plot_efficiency_type = Scatter(plantlist_for_efficiency_analysis, \n",
    "                              x='commissioned_float', \n",
    "                              y='efficiency_net',\n",
    "                              color='fuel', \n",
    "                              title='Efficiency vs commissioning year', \n",
    "                              xlabel='Year', \n",
    "                              ylabel='Efficiency',\n",
    "                              legend=\"top_left\",\n",
    "                              height=700,\n",
    "                              width=1000)\n",
    "show(plot_efficiency_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.8.1.3 Determine least-squares approximation based on researched data (planned)\n",
    "This code-section is commented out at the moment, as this feature is still in the planning phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#import statsmodels.api as sm\n",
    "#from statsmodels.formula.api import ols\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#olslist = {}\n",
    "#for fuelnames in plantlist[\"fuel\"].unique():\n",
    "#    plantlist_for_efficiency_analysis = plantlist[(plantlist.fuel==fuelnames) & (plantlist.efficiency_net.notnull()==True)]\n",
    "#    if len(plantlist_for_efficiency_analysis.index)>=4:\n",
    "#        efficiencyestimate = ols(\"efficiency_net  ~  commissioned_float + chp +uba_technology \", plantlist_for_efficiency_analysis).fit()\n",
    "#        olslist[fuelnames]=efficiencyestimate\n",
    "#        print(efficiencyestimate.summary())\n",
    "\n",
    "        \n",
    "#        fig, ax = plt.subplots()\n",
    "#        fig = sm.graphics.plot_fit(efficiencyestimate, 'commissioned_float',  ax=ax)\n",
    "#        plt.ylabel(\"Efficiency\")\n",
    "#        plt.xlabel(\"Commissioned\")\n",
    "#        plt.title(fuelnames)\n",
    "#        plt.legend(['Data', 'Fitted model'], loc=2)\n",
    "#        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 8.8.1.4 Apply efficiency approximation from least squares approximation (planned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Planned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.8.2 Efficiencies from literature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jonas Egerer, Clemens Gerbaulet, Richard Ihlenburg, Friedrich Kunz, Benjamin Reinhard, Christian von Hirschhausen, Alexander Weber, Jens Weibezahn (2014): **Electricity Sector Data for Policy-Relevant Modeling: Data Documentation and Applications to the German and European Electricity Markets**. DIW Data Documentation 72, Berlin, Germany."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.8.2.1 Import data\n",
    "For each energy source - technology combination two values are read, to be applied as a linear approximation based on the year of commissioning. Therefore, the efficiency is made up of the efficiency_intercept (the efficiency at \"year zero\") plus the efficiency_slope multiplied by the year of commissioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_efficiencies_literature = pd.read_csv(os.path.join('input','input_efficiency_literature_by_fuel_technology.csv'),\n",
    "                                     sep=',',  # CSV field separator, default is ','\n",
    "                                     decimal='.',  # Decimal separator, default is '.')  \n",
    "                                     encoding='utf8')\n",
    "data_efficiencies_literature['technology'] = data_efficiencies_literature['technology'].str.upper()\n",
    "data_efficiencies_literature = data_efficiencies_literature.set_index(['fuel','technology'])\n",
    "data_efficiencies_literature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.8.2.2 Apply efficiency approximation from literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plantlist = plantlist.join(data_efficiencies_literature,on=['fuel','technology'])\n",
    "plantlist['efficiency_literature'] = plantlist['efficiency_intercept'] + plantlist['efficiency_slope']*plantlist[['commissioned_float','retrofit_float']].max(axis=1)\n",
    "plantlist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.9 Add geodata\n",
    "\n",
    "The locations of power plants have been researched manually, these are now added to the output. Checking was done visually using satellite imagery and other mapping material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_plant_locations = pd.read_csv(os.path.join('input','input_plant_locations_de.csv'),\n",
    "                                     sep=',',  # CSV field separator, default is ','\n",
    "                                     decimal='.',  # Decimal separator, default is '.')  \n",
    "                                     encoding='utf8')\n",
    "\n",
    "data_plant_locations = data_plant_locations.set_index('id')\n",
    "\n",
    "data_plant_locations['lat'] = pd.to_numeric(data_plant_locations['lat'], \n",
    "                                            errors='coerce')\n",
    "data_plant_locations['lon'] = pd.to_numeric(data_plant_locations['lon'], \n",
    "                                            errors='coerce')\n",
    "\n",
    "plantlist = pd.merge(plantlist, \n",
    "                     data_plant_locations, \n",
    "                     left_index=True, \n",
    "                     right_index=True, \n",
    "                     how='left')\n",
    "plantlist.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Define final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Merge uba_name_aggregate and uba_name\n",
    "plantlist.loc[plantlist['uba_name_aggregate'].isnull(), 'uba_name_aggregate'] = plantlist['uba_name']\n",
    "\n",
    "# Drop columns not relevant for output\n",
    "colsToDrop = ['bnetza_id',\n",
    "              'capacity',\n",
    "              'uba_name',\n",
    "              'uba_capacity_original',\n",
    "              'uba_chp_capacity_original',\n",
    "              'uba_city', \n",
    "              'uba_commissioned', \n",
    "              'uba_company', \n",
    "              'uba_company_aggregate', \n",
    "              'uba_fuel', \n",
    "              'uba_postcode', \n",
    "              'uba_state', \n",
    "              'uba_technology', \n",
    "              'uba_technology_aggregate', \n",
    "              'retrofit',\n",
    "              'uba_commissioned_1', \n",
    "              'uba_commissioned_2', \n",
    "              'uba_commissioned_3', \n",
    "              'commissioned_1', \n",
    "              'commissioned_2', \n",
    "              'commissioned_3', \n",
    "              'fuel_basis', \n",
    "              'fuel_multiple1', \n",
    "              'fuel_multiple2',\n",
    "              'efficiency_gross',\n",
    "              'efficiency_intercept',\n",
    "              'efficiency_slope',\n",
    "              'source_type',\n",
    "              'date'\n",
    "             ]\n",
    "plantlist = plantlist.drop(colsToDrop, axis=1)\n",
    "\n",
    "# Rename columns\n",
    "# FRAUKE: Hätten die schon früher so heißen können die Spalten?\n",
    "plantlist = plantlist.rename(columns={'commissioned': 'commissioned_original', \n",
    "                                      'commissioned_float': 'commissioned', \n",
    "                                      'retrofit_float': 'retrofit', \n",
    "                                      'capacity_float': 'capacity_net_bnetza',\n",
    "                                      'uba_capacity': 'capacity_gross_uba', \n",
    "                                      'uba_chp_capacity': 'chp_capacity_uba', \n",
    "                                      'efficiency_net': 'efficiency_data', \n",
    "                                      'efficiency_literature': 'efficiency_estimate', \n",
    "                                      'uba_name_aggregate': 'name_uba',\n",
    "                                      'name': 'name_bnetza',\n",
    "                                      'block': 'block_bnetza',\n",
    "                                     })\n",
    "\n",
    "# Sort columns\n",
    "columns_sorted = [\n",
    "                 'country_code',\n",
    "                 'company',\n",
    "                 'name_bnetza',\n",
    "                 'block_bnetza',\n",
    "                 'name_uba',\n",
    "                 'postcode',\n",
    "                 'city',\n",
    "                 'street',\n",
    "                 'state',\n",
    "                 'commissioned_original',\n",
    "                 'commissioned',\n",
    "                 'retrofit',\n",
    "                 'shutdown',\n",
    "                 'status',\n",
    "                 'fuel',\n",
    "                 'technology',\n",
    "                 'type',\n",
    "                 'eeg',\n",
    "                 'chp',\n",
    "                 'capacity_net_bnetza',\n",
    "                 'capacity_gross_uba',\n",
    "                 'chp_capacity_uba',\n",
    "                 'merge_comment',\n",
    "                 'efficiency_data',\n",
    "                 'efficiency_source',\n",
    "                 'efficiency_estimate',\n",
    "                 'network_node',\n",
    "                 'voltage',\n",
    "                 'network_operator',\n",
    "                 'lat',\n",
    "                 'lon',\n",
    "                 'comment']\n",
    "plantlist = plantlist.reindex(columns=columns_sorted)\n",
    "\n",
    "plantlist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9.1 Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.1 Capacities by plant status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Todo: Use Bokeh\n",
    "\n",
    "pivot_status_capacity = pd.pivot_table(\n",
    "                        plantlist, \n",
    "                        values='capacity_net_bnetza',\n",
    "                        columns='status',\n",
    "                        index='fuel', \n",
    "                        aggfunc=np.sum\n",
    "                        )\n",
    "pivot_status_capacity.sort_values(by='operating', inplace=True, ascending=0)\n",
    "pivot_status_capacity_plot=pivot_status_capacity.plot(kind='barh', \n",
    "                                                      stacked=True,\n",
    "                                                      legend=True, \n",
    "                                                      figsize=(12, 6))\n",
    "pivot_status_capacity_plot.set_xlabel(\"MW\")\n",
    "pivot_status_capacity_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.2 Power plant age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Todo: Use Bokeh\n",
    "\n",
    "## Vorschlag: Commissioned in 5-Jahres Abschnitten darstellen\n",
    "##            oder lieber die kumulierte Kapazität als Linie über die Jahre, eine Linie\n",
    "##            pro Technologie und die Farben für fuel definieren damit die unterschiedlich\n",
    "##            sind\n",
    "\n",
    "plantlist_filtered = plantlist  \n",
    "pivot_age_capacity = pd.pivot_table(\n",
    "                        plantlist_filtered, \n",
    "                        values='capacity_net_bnetza',\n",
    "                        columns='fuel',\n",
    "                        index='commissioned', \n",
    "                        aggfunc=np.sum,\n",
    "                        dropna=True\n",
    "                        )\n",
    "\n",
    "pivot_age_capacity_plot=pivot_age_capacity.plot(kind='bar', \n",
    "                                                stacked=True,\n",
    "                                                legend=True, \n",
    "                                                figsize=(17, 10))\n",
    "pivot_age_capacity_plot.set_ylabel(\"MW\")\n",
    "pivot_age_capacity_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.3 Block size vs year of commissioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chart is suitable to check outliers of commissioning years and block sizes. \n",
    "In theory, there should be no unexpected values, e.g. all commissioning years should be greater than 1900. \n",
    "Block sizes above 2000 MW are also unlikely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Todo: Use a better color pallette\n",
    "\n",
    "plantlist_for_plot = plantlist.copy(deep=True)\n",
    "plantlist_for_plot['capacity_float'] = pd.to_numeric(plantlist_for_plot['capacity_net_bnetza'], \n",
    "                                                     errors='coerce')\n",
    "plantlist_for_plot['commissioned_float'] = pd.to_numeric(plantlist_for_plot['commissioned'], \n",
    "                                                         errors='coerce')\n",
    "plot_blocksize_year = Scatter(plantlist_for_plot,  \n",
    "                              x='commissioned_float', \n",
    "                              y='capacity_float',\n",
    "                              color='fuel', \n",
    "                              title='Block-Size vs Year of Commissioning', \n",
    "                              xlabel='Year', \n",
    "                              ylabel='MW',\n",
    "                              legend=\"top_left\",\n",
    "                              height=500,\n",
    "                              width=700)\n",
    "show(plot_blocksize_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Logical checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2.1 Every power plant needs a capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all entries with zero capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plantlist[plantlist.capacity_net_bnetza == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2.2 Commissioning Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Show all Plants with commisioning dates below 1900 \n",
    "plantlist[plantlist['commissioned'] <= 1900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show all Plants with invalid commisioning dates\n",
    "plantlist[plantlist['commissioned'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2.3 Compare UBA and BNetzA data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2.3.1 Postcodes of BNetzA and UBA lists should match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Todo: When implemented write a marker in the comment column\n",
    "\n",
    "# List all entries with diverging postcodes (if a postcode is given)\n",
    "# plantlist[(plantlist['uba_postcode'].notnull() == True) & (pd.to_numeric(plantlist.postcode, errors='coerce') != pd.to_numeric(plantlist.uba_postcode, errors='coerce'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2.3.2 Compare Installed capacities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Todo: improve this comparison, it creates many false positives\n",
    "\n",
    "capacitycomparison = pd.DataFrame(plantlist.capacity_net_bnetza / plantlist.capacity_gross_uba)\n",
    "capacitycomparison['Name'] = plantlist.name_bnetza\n",
    "capacitycomparison['Block'] = plantlist.block_bnetza\n",
    "capacitycomparison['BnetzaCapacity'] = plantlist.capacity_net_bnetza\n",
    "capacitycomparison['UBACapacity'] = plantlist.capacity_gross_uba\n",
    "capacitycomparison.dropna(inplace=True)\n",
    "capacitycomparison.sort_values(by=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 10. Documenting the data package (meta data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We document the data packages meta data in the specific format JSON as proposed by the Open Knowledge Foundation. See the Frictionless Data project by OKFN (http://data.okfn.org/) and the Data Package specifications (http://dataprotocols.org/data-packages/) for more details.\n",
    "\n",
    "In order to keep the notebook more readable, we first formulate the metadata in the human-readable YAML format using a multi-line string. We then parse the string into a Python dictionary and save that to disk as a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we define meta data of the resulting data package.\n",
    "# The meta data follows the specification at:\n",
    "# http://dataprotocols.org/data-packages/\n",
    "metadata_file = open(os.path.join('input','metadata.txt'), \"r\")\n",
    "metadata_line = metadata_file.read()\n",
    "metadata = yaml.load(metadata_line)\n",
    "\n",
    "datapackage_json = json.dumps(metadata, indent=4, separators=(',', ': '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Write the results to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_path = 'output'\n",
    "\n",
    "# Write the result to file\n",
    "plantlist.to_csv(os.path.join(output_path, 'conventional_power_plants_germany.csv'), encoding='utf-8')\n",
    "\n",
    "# Write the results to excel file\n",
    "plantlist.to_excel(os.path.join(output_path, 'conventional_power_plants_germany.xlsx'), sheet_name='plants')\n",
    "\n",
    "# Write the results to sqlite database\n",
    "plantlist.to_sql(os.path.join(output_path , 'conventional_power_plants_germany'),\n",
    "                 sqlite3.connect(os.path.join(output_path , 'conventional_power_plants_germany.sqlite')),\n",
    "                 if_exists=\"replace\") \n",
    "\n",
    "# Write the information of the metadata\n",
    "with open(os.path.join(output_path, 'datapackage.json'), 'w') as f:\n",
    "    f.write(datapackage_json)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
